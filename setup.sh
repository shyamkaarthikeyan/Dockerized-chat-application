#!/bin/bash

# Real-time Chat Application Setup Script
# This script automates the deployment and initial setup

set -e

echo "ğŸš€ Starting Real-time Chat Application Setup..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "âŒ Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

echo "âœ… Docker and Docker Compose are available"

# Start the services
echo "ğŸ“¦ Starting all services with Docker Compose..."
docker-compose up -d

echo "â³ Waiting for services to start..."
sleep 10

# Wait for Ollama to be ready
echo "ğŸ¤– Waiting for Ollama to be ready..."
max_attempts=30
attempt=0

while [ $attempt -lt $max_attempts ]; do
    if curl -f http://localhost:11434/api/tags >/dev/null 2>&1; then
        echo "âœ… Ollama is ready!"
        break
    fi
    
    attempt=$((attempt + 1))
    echo "â³ Attempt $attempt/$max_attempts - Ollama not ready yet..."
    sleep 10
done

if [ $attempt -eq $max_attempts ]; then
    echo "âŒ Ollama failed to start within expected time"
    echo "ğŸ“‹ Check logs with: docker-compose logs ollama"
    exit 1
fi

# Pull the default LLM model
echo "ğŸ“¥ Pulling default LLM model (llama3.2)..."
docker exec ollama ollama pull llama3.2

# Optional: Pull additional models
read -p "ğŸ¤” Do you want to pull additional models? (y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ğŸ“¥ Pulling additional models..."
    docker exec ollama ollama pull mistral
    docker exec ollama ollama pull neural-chat
    echo "âœ… Additional models downloaded!"
fi

# Check if all services are healthy
echo "ğŸ” Checking service health..."

# Check backend
if curl -f http://localhost:3001/health >/dev/null 2>&1; then
    echo "âœ… Backend is healthy"
else
    echo "âš ï¸ Backend health check failed"
fi

# Check frontend
if curl -f http://localhost:8501/_stcore/health >/dev/null 2>&1; then
    echo "âœ… Frontend is healthy"
else
    echo "âš ï¸ Frontend health check failed"
fi

echo ""
echo "ğŸ‰ Setup complete!"
echo ""
echo "ğŸ“‹ Access your application:"
echo "   Frontend: http://localhost:8501"
echo "   Backend Health: http://localhost:3001/health"
echo "   Ollama API: http://localhost:11434/api/tags"
echo ""
echo "ğŸ“– Useful commands:"
echo "   View logs: docker-compose logs -f"
echo "   Stop services: docker-compose down"
echo "   Restart: docker-compose restart"
echo ""
echo "ğŸš€ Happy chatting with your local LLM!"